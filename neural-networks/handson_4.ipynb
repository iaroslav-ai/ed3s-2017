{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural networks, 1D CNN\n",
    "\n",
    "RNN's are well suited for processing data which consists of sequences. These models process sequence element by element, while keeping the memory of the elements that the network has already seen. \n",
    "One dimensional convolutional layers can also be applied to sequences, same as they are applied to 2d images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset used\n",
    "\n",
    "IMDB sentiment recognition dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GRU, Input, Conv1D, MaxPool1D, Embedding, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# prepare the data\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=20000)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=80)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=X_train[0].shape)\n",
    "h = x\n",
    "h = Embedding(20000, 128)(h)\n",
    "\n",
    "mode = 'gru'\n",
    "\n",
    "if mode == 'gru':\n",
    "    h = GRU(64)(h)\n",
    "else:\n",
    "    h = Conv1D(32, 5, strides=5)(h)\n",
    "    h = MaxPool1D(5)(h)\n",
    "    h = LeakyReLU()(h)\n",
    "    \n",
    "    h = Flatten()(h)\n",
    "    \n",
    "h = Dense(2, activation='softmax')(h)\n",
    "\n",
    "# get the trivial accuracy\n",
    "dummy_model = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "dummy_score = dummy_model.score(X_test, y_test)\n",
    "print('Dummy test accuracy:', dummy_score)\n",
    "\n",
    "model = Model(inputs=x, outputs=h)\n",
    "\n",
    "# compile computational graph of NN\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train NN\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# evaluate your NN\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
